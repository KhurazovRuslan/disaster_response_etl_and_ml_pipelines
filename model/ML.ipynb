{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a machine learning part of NLP disaster response profect for Data Science nandegree. The first part, EDA and ETL part, can be found <a href='http://localhost:8888/notebooks/Desktop/Pipelines_testing/data/EDA%20and%20ETL.ipynb'>here</a>. As mentioned in previous notebook, data is provided by <a href='https://appen.com/'>Figure Eight (aquired by Appen)</a> and the objective of the project is to build a web app that will correctly classify disaster messages for a better and quicker response. This notebook covers text preprocessing, pipeline building, evaluating, tuning and testing of classifier. Also the notebook will describe steps for ML pipeline. According to ETL pipeline, our data is now stored in disaster_messages table in DisasterResponse.db database file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import the libraries and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HurazovRuslan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HurazovRuslan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HurazovRuslan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HurazovRuslan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw to\n",
      "[nltk_data]     C:\\Users\\HurazovRuslan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download(['punkt','wordnet','stopwords','averaged_perceptron_tagger','omw'])\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import recall_score, f1_score, brier_score_loss, roc_auc_score\n",
    "from scipy.stats import zscore\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0        0      0            0             0                 0  ...   \n",
       "1        0      0            1             0                 0  ...   \n",
       "2        0      0            0             0                 0  ...   \n",
       "3        1      0            1             0                 1  ...   \n",
       "4        0      0            0             0                 0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "\n",
    "# connect to the database\n",
    "engine = create_engine(f'sqlite:///https://github.com/KhurazovRuslan/disaster_response_etl_and_ml_pipelines/blob/main/data/DisasterResponse.db')\n",
    "# C:/Users/HurazovRuslan/Desktop/Pipelines_testing/data/DisasterResponse.db\n",
    "# sql query\n",
    "query = 'SELECT * FROM disaster_messages'\n",
    "\n",
    "# load data into dataframe\n",
    "df = pd.read_sql(sql=query, con=engine)\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26216 entries, 0 to 26215\n",
      "Data columns (total 40 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   id                      26216 non-null  int64 \n",
      " 1   message                 26216 non-null  object\n",
      " 2   original                10170 non-null  object\n",
      " 3   genre                   26216 non-null  object\n",
      " 4   related                 26216 non-null  int64 \n",
      " 5   request                 26216 non-null  int64 \n",
      " 6   offer                   26216 non-null  int64 \n",
      " 7   aid_related             26216 non-null  int64 \n",
      " 8   medical_help            26216 non-null  int64 \n",
      " 9   medical_products        26216 non-null  int64 \n",
      " 10  search_and_rescue       26216 non-null  int64 \n",
      " 11  security                26216 non-null  int64 \n",
      " 12  military                26216 non-null  int64 \n",
      " 13  child_alone             26216 non-null  int64 \n",
      " 14  water                   26216 non-null  int64 \n",
      " 15  food                    26216 non-null  int64 \n",
      " 16  shelter                 26216 non-null  int64 \n",
      " 17  clothing                26216 non-null  int64 \n",
      " 18  money                   26216 non-null  int64 \n",
      " 19  missing_people          26216 non-null  int64 \n",
      " 20  refugees                26216 non-null  int64 \n",
      " 21  death                   26216 non-null  int64 \n",
      " 22  other_aid               26216 non-null  int64 \n",
      " 23  infrastructure_related  26216 non-null  int64 \n",
      " 24  transport               26216 non-null  int64 \n",
      " 25  buildings               26216 non-null  int64 \n",
      " 26  electricity             26216 non-null  int64 \n",
      " 27  tools                   26216 non-null  int64 \n",
      " 28  hospitals               26216 non-null  int64 \n",
      " 29  shops                   26216 non-null  int64 \n",
      " 30  aid_centers             26216 non-null  int64 \n",
      " 31  other_infrastructure    26216 non-null  int64 \n",
      " 32  weather_related         26216 non-null  int64 \n",
      " 33  floods                  26216 non-null  int64 \n",
      " 34  storm                   26216 non-null  int64 \n",
      " 35  fire                    26216 non-null  int64 \n",
      " 36  earthquake              26216 non-null  int64 \n",
      " 37  cold                    26216 non-null  int64 \n",
      " 38  other_weather           26216 non-null  int64 \n",
      " 39  direct_report           26216 non-null  int64 \n",
      "dtypes: int64(37), object(3)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have 40 columns and 36 of them are different classes we need to classify. As mentioned in <a href='http://localhost:8888/notebooks/Desktop/Pipelines_testing/data/EDA%20and%20ETL.ipynb'>previous notebook</a>, we'll drop 'child_alone' column for simplicity as it only has label 0. The column to work with for features is 'message' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('child_alone', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to use TF-IDF for feature extraction but the text has to be preprocessed first. I need to standardize the case of the letters, expand contractions, get rid of all non-alphabetic characters, lemmatize the words and throw out stop words. All this steps were done in <a href='http://localhost:8888/notebooks/Desktop/Pipelines_testing/data/EDA%20and%20ETL.ipynb'>previous notebook</a> for exploritory analysis and we figured that there are some words to be added to stop words vocabulary and I want to use word tags before lemmatizing this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions and variables for text preprocessing\n",
    "\n",
    "# additional stop words\n",
    "add_stopwords = ['', ' ', 'say', 's', 'u', 'ap', 'afp', '...', 'n', '\\\\','http','bit','ly','like','know']\n",
    "\n",
    "# stop_words\n",
    "stop_words = ENGLISH_STOP_WORDS.union(add_stopwords)\n",
    "\n",
    "# contractions dictionary to replace short versions with full versions\n",
    "contractions_dict = {\n",
    "  \"i'm\":\"i am\",\n",
    "  \"i'll\":\"i will\",  \n",
    "  \"ain't\": \"am not\",\n",
    "  \"aren't\": \"are not\",\n",
    "  \"can't\": \"cannot\",\n",
    "  \"can't've\": \"cannot have\",\n",
    "  \"'cause\": \"because\",\n",
    "  \"could've\": \"could have\",\n",
    "  \"couldn't\": \"could not\",\n",
    "  \"couldn't've\": \"could not have\",\n",
    "  \"didn't\": \"did not\",\n",
    "  \"doesn't\": \"does not\",\n",
    "  \"don't\": \"do not\",\n",
    "  \"hadn't\": \"had not\",\n",
    "  \"hadn't've\": \"had not have\",\n",
    "  \"hasn't\": \"has not\",\n",
    "  \"haven't\": \"have not\",\n",
    "  \"he'd\": \"he would\",\n",
    "  \"he'd've\": \"he would have\",\n",
    "  \"he'll\": \"he will\",\n",
    "  \"he'll've\": \"he will have\",\n",
    "  \"he's\": \"he is\",\n",
    "  \"how'd\": \"how did\",\n",
    "  \"how'd'y\": \"how do you\",\n",
    "  \"how'll\": \"how will\",\n",
    "  \"how's\": \"how is\",\n",
    "  \"i'd\": \"I would\",\n",
    "  \"i'd've\": \"I would have\",\n",
    "  \"i'll\": \"I will\",\n",
    "  \"i'll've\": \"I will have\",\n",
    "  \"i'm\": \"I am\",\n",
    "  \"i've\": \"I have\",\n",
    "  \"isn't\": \"is not\",\n",
    "  \"it'd\": \"it had\",\n",
    "  \"it'd've\": \"it would have\",\n",
    "  \"it'll\": \"it will\",\n",
    "  \"it'll've\": \"it will have\",\n",
    "  \"it's\": \"it is\",\n",
    "  \"let's\": \"let us\",\n",
    "  \"ma'am\": \"madam\",\n",
    "  \"mayn't\": \"may not\",\n",
    "  \"might've\": \"might have\",\n",
    "  \"mightn't\": \"might not\",\n",
    "  \"mightn't've\": \"might not have\",\n",
    "  \"must've\": \"must have\",\n",
    "  \"mustn't\": \"must not\",\n",
    "  \"mustn't've\": \"must not have\",\n",
    "  \"needn't\": \"need not\",\n",
    "  \"needn't've\": \"need not have\",\n",
    "  \"o'clock\": \"of the clock\",\n",
    "  \"oughtn't\": \"ought not\",\n",
    "  \"oughtn't've\": \"ought not have\",\n",
    "  \"shan't\": \"shall not\",\n",
    "  \"sha'n't\": \"shall not\",\n",
    "  \"shan't've\": \"shall not have\",\n",
    "  \"she'd\": \"she would\",\n",
    "  \"she'd've\": \"she would have\",\n",
    "  \"she'll\": \"she will\",\n",
    "  \"she'll've\": \"she will have\",\n",
    "  \"she's\": \"she is\",\n",
    "  \"should've\": \"should have\",\n",
    "  \"shouldn't\": \"should not\",\n",
    "  \"shouldn't've\": \"should not have\",\n",
    "  \"so've\": \"so have\",\n",
    "  \"so's\": \"so is\",\n",
    "  \"that'd\": \"that would\",\n",
    "  \"that'd've\": \"that would have\",\n",
    "  \"that's\": \"that is\",\n",
    "  \"there'd\": \"there had\",\n",
    "  \"there'd've\": \"there would have\",\n",
    "  \"there's\": \"there is\",\n",
    "  \"they'd\": \"they would\",\n",
    "  \"they'd've\": \"they would have\",\n",
    "  \"they'll\": \"they will\",\n",
    "  \"they'll've\": \"they will have\",\n",
    "  \"they're\": \"they are\",\n",
    "  \"they've\": \"they have\",\n",
    "  \"to've\": \"to have\",\n",
    "  \"wasn't\": \"was not\",\n",
    "  \"we'd\": \"we had\",\n",
    "  \"we'd've\": \"we would have\",\n",
    "  \"we'll\": \"we will\",\n",
    "  \"we'll've\": \"we will have\",\n",
    "  \"we're\": \"we are\",\n",
    "  \"we've\": \"we have\",\n",
    "  \"weren't\": \"were not\",\n",
    "  \"what'll\": \"what will\",\n",
    "  \"what'll've\": \"what will have\",\n",
    "  \"what're\": \"what are\",\n",
    "  \"what's\": \"what is\",\n",
    "  \"what've\": \"what have\",\n",
    "  \"when's\": \"when is\",\n",
    "  \"when've\": \"when have\",\n",
    "  \"where'd\": \"where did\",\n",
    "  \"where's\": \"where is\",\n",
    "  \"where've\": \"where have\",\n",
    "  \"who'll\": \"who will\",\n",
    "  \"who'll've\": \"who will have\",\n",
    "  \"who's\": \"who is\",\n",
    "  \"who've\": \"who have\",\n",
    "  \"why's\": \"why is\",\n",
    "  \"why've\": \"why have\",\n",
    "  \"will've\": \"will have\",\n",
    "  \"won't\": \"will not\",\n",
    "  \"won't've\": \"will not have\",\n",
    "  \"would've\": \"would have\",\n",
    "  \"wouldn't\": \"would not\",\n",
    "  \"wouldn't've\": \"would not have\",\n",
    "  \"y'all\": \"you all\",\n",
    "  \"y'alls\": \"you alls\",\n",
    "  \"y'all'd\": \"you all would\",\n",
    "  \"y'all'd've\": \"you all would have\",\n",
    "  \"y'all're\": \"you all are\",\n",
    "  \"y'all've\": \"you all have\",\n",
    "  \"you'd\": \"you had\",\n",
    "  \"you'd've\": \"you would have\",\n",
    "  \"you'll\": \"you you will\",\n",
    "  \"you'll've\": \"you you will have\",\n",
    "  \"you're\": \"you are\",\n",
    "  \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "# compile\n",
    "c_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "# function to expand contractions\n",
    "def expand_contractions(message, c_re=c_re):\n",
    "    \n",
    "    \"\"\"\n",
    "    Expands contractions according to pre-compiled dictionary.\n",
    "    message - string, text where contractions have to be expanded.\n",
    "    \"\"\"\n",
    "    \n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    \n",
    "    return c_re.sub(replace, message)\n",
    "\n",
    "\n",
    "# a function to replace nltk pos tags with corresponding word_net pos tags (to use with WordNetLemmatizer)\n",
    "def word_net_tags(nltk_tag):\n",
    "    \n",
    "    \"\"\"\n",
    "    Replaces ntlk pos tag with corresponding WordNet pos tag\n",
    "    nltk_tag - nltk pos tag\n",
    "    Returns a corresponding WordNet pos tag \n",
    "    \"\"\"\n",
    "    \n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "# lemmatizing function\n",
    "def lemmatize(tagged_text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Lemmatizes tokens\n",
    "    tagged_text - list of tokens and their nltk po tags\n",
    "    Returns list of lemmatized tokens \n",
    "    \"\"\"\n",
    "    \n",
    "    # list of lemmatized tokens\n",
    "    lem_tokens = []\n",
    "    \n",
    "    # a for loop to populate the list\n",
    "    for word,tag in tagged_text:\n",
    "        \n",
    "        word_net_tag = word_net_tags(tag)\n",
    "        \n",
    "        if word_net_tag is None:\n",
    "            lem_tokens.append(WordNetLemmatizer().lemmatize(word))\n",
    "            \n",
    "        else:\n",
    "            lem_tokens.append(WordNetLemmatizer().lemmatize(word, pos=word_net_tag))\n",
    "            \n",
    "            \n",
    "    return lem_tokens\n",
    "\n",
    "\n",
    "# text processing function for TfidfVectorizer\n",
    "def process_text(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    text - string\n",
    "    Removes all non-alphabetica characters and stop words, lemmatizes the words in the text and tokenizes them\n",
    "    Returns clean, lemmatized tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    # decontract text\n",
    "    text = expand_contractions(text.lower())\n",
    "           \n",
    "    # keep only letters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "            \n",
    "    # tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "            \n",
    "    # nltk pos tags\n",
    "    tokens = nltk.pos_tag(tokens)\n",
    "            \n",
    "    # change nltk to wordnet pos tags and lemmatize\n",
    "    tokens = lemmatize(tokens)\n",
    "            \n",
    "    # remove stop words and return clean tokens\n",
    "    return [token for token in tokens if token not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I want to use several different classifiers in pipeline first. Then choose the best one and try ti tune it for a better performance. Our data is highly imbalanced and the number of positive responses (label 1) is very low for each class. I thing that our classifier has to be very good in classifing labels 1 specifically as it could have dangerous consequences to miss out a true disaster message. So I chose recall score ('weighted') as the main metric. The idea is to be able identify all positive labels even if we'll have some false positives on the way. F1 score ('weighted') will also be displayed as one of secondary metrics. ROC AUC score is to show the quality of predictions. I also want to use it for web app to show the probability of the text to be a disaster message. Brier score loss will be used as secondary metric for probabilities. Accuracy score will also be displayed in ML pipeline because the project requires it but I think because of high imbalance in data accuracy score is not a good metric here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to train and evaluate different classifiers\n",
    "\n",
    "\n",
    "# function to evaluate probabilities\n",
    "def evaluate_proba(y_test,y_proba,metric):\n",
    "    \"\"\"\n",
    "    Evaluates predicted probabilities\n",
    "    y_test - true labels\n",
    "    y_proba - predicted probabilities\n",
    "    metric - string, one of 2 metrics, 'brier_score_loss' or 'roc_auc_score'\n",
    "    Returns the mean score of each predicted probabilities' labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # list of scores of each label\n",
    "    scores = []\n",
    "    \n",
    "    # a for loop to populate the list\n",
    "    for i,category in enumerate(list(y_test.columns)):\n",
    "        \n",
    "        # if roc_auc_score chosen\n",
    "        if metric=='roc_auc_score':\n",
    "            scores.append(roc_auc_score(y_test[category],y_proba[i][:,1]))\n",
    "            \n",
    "        elif metric=='brier_score_loss':\n",
    "            scores.append(brier_score_loss(y_test[category],y_proba[i][:,1]))\n",
    "            \n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def score_model(models,X_train,y_train,X_test,y_test):\n",
    "    \"\"\"\n",
    "    Scores different models.\n",
    "    Models are trained on NLP pipeline with multioutputclassifier output\n",
    "    Returns a dataframe with model name and recall, roc_auc, f1 scores and brier_score_loss \n",
    "    \n",
    "    \n",
    "    models - a dictionary of different classifiers\n",
    "    X_train, y_train - features and labels to train on\n",
    "    X_test, y_test - features and labels to test for scoring\n",
    "    \"\"\"\n",
    "    \n",
    "    # lists of models' names and scores\n",
    "    model_name, recall, roc_auc, f1, brier_loss = [],[],[],[],[]\n",
    "    \n",
    "    # fit each model and populate score lists\n",
    "    for label,model in models.items():\n",
    "        \n",
    "        model_name.append(label)\n",
    "        \n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('features',TfidfVectorizer(tokenizer=process_text, ngram_range=(1,2), max_df=0.95, min_df=2)),\n",
    "            ('clf',MultiOutputClassifier(estimator=model))\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train,y_train)\n",
    "        \n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        y_prob = np.array(pipeline.predict_proba(X_test))\n",
    "        \n",
    "        recall.append(recall_score(y_test,y_pred, average='weighted'))\n",
    "        roc_auc.append(evaluate_proba(y_test,y_prob,metric='roc_auc_score'))\n",
    "        f1.append(f1_score(y_test,y_pred, average='weighted'))\n",
    "        brier_loss.append(evaluate_proba(y_test,y_prob,metric='brier_score_loss'))\n",
    "        \n",
    "        \n",
    "        \n",
    "    # dataframe\n",
    "    df = pd.DataFrame({'model_name':model_name,\n",
    "                       'recall_score':recall,\n",
    "                       'roc_auc_score':roc_auc,\n",
    "                       'f1_score':f1,\n",
    "                       'brier_score_loss':brier_loss})\n",
    "    df = df.sort_values(by=['recall_score','roc_auc_score','f1_score'], ascending=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to train\n",
    "models = {\n",
    "    'Logistic regression':LogisticRegression(random_state=42),\n",
    "    'Decision tree':DecisionTreeClassifier(random_state=42),\n",
    "    'Random forest':RandomForestClassifier(random_state=42),\n",
    "    'Adaboost':AdaBoostClassifier(random_state=42),\n",
    "    'Multinomial Naive Bayes':MultinomialNB(),\n",
    "    'XGBoost':XGBClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X = df['message']\n",
    "y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# need some data for evaluation\n",
    "X_test, X_eval, y_test, y_eval = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37min 24s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>brier_score_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.603534</td>\n",
       "      <td>0.830475</td>\n",
       "      <td>0.641227</td>\n",
       "      <td>0.040310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.596386</td>\n",
       "      <td>0.662217</td>\n",
       "      <td>0.601412</td>\n",
       "      <td>0.069652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.583133</td>\n",
       "      <td>0.809574</td>\n",
       "      <td>0.618481</td>\n",
       "      <td>0.225074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>0.533092</td>\n",
       "      <td>0.856560</td>\n",
       "      <td>0.577866</td>\n",
       "      <td>0.041543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>0.531566</td>\n",
       "      <td>0.813457</td>\n",
       "      <td>0.575077</td>\n",
       "      <td>0.041890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.398474</td>\n",
       "      <td>0.660139</td>\n",
       "      <td>0.415164</td>\n",
       "      <td>0.053886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model_name  recall_score  roc_auc_score  f1_score  \\\n",
       "5                  XGBoost      0.603534       0.830475  0.641227   \n",
       "1            Decision tree      0.596386       0.662217  0.601412   \n",
       "3                 Adaboost      0.583133       0.809574  0.618481   \n",
       "0      Logistic regression      0.533092       0.856560  0.577866   \n",
       "2            Random forest      0.531566       0.813457  0.575077   \n",
       "4  Multinomial Naive Bayes      0.398474       0.660139  0.415164   \n",
       "\n",
       "   brier_score_loss  \n",
       "5          0.040310  \n",
       "1          0.069652  \n",
       "3          0.225074  \n",
       "0          0.041543  \n",
       "2          0.041890  \n",
       "4          0.053886  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "scores_bow = score_model(models,X_train,y_train,X_test,y_test)\n",
    "scores_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, XGBoost looks very good across the board. It shows highest recall and F1 scores, second highest roc_auc score and lowest brier score loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try adding word count as a feature and see if that's going to improve our scores. We'll have to create a custom object with 'fit' and 'transform' methods in order to add it into the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCount(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"\n",
    "    Counts number of words in a message.\n",
    "    Returns standardized number of words in message. Uses z-score for standardization\n",
    "    \"\"\"\n",
    "    \n",
    "    # constractor function\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # fit method\n",
    "    def fit(self,df,y_true=None):\n",
    "        \"\"\"\n",
    "        df - Series of messages or texts\n",
    "        Returns itself\n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    # transform method\n",
    "    def transform(self,df,y_true=None):\n",
    "        \"\"\"\n",
    "        df - Series of messages or texts\n",
    "        Returns list of stardardized numbers of words in each element of df\n",
    "        \"\"\"\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "        # word count\n",
    "        word_count = np.array([len(str(text).split(' ')) for text in self.df])\n",
    "        \n",
    "        # scipy's zscore to stardardize the numbers\n",
    "        word_count = zscore(word_count)\n",
    "        \n",
    "        # return a 2d array\n",
    "        return np.array(word_count[:,None], copy=False, subok=True, ndmin=2)\n",
    "    \n",
    "    # fit_transform\n",
    "    def fit_transform(self,df,y=None):\n",
    "        \"\"\"\n",
    "        df - Series of messages or texts\n",
    "        Performs a fitting and transformation over df\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.fit(df,y).transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now adding new object to pipeline and score classifiers. But this time I won't be using Multinomial Naive Bayes classifier. Mainly because there might be negative values as features (after stardardizing word count) and Multinomial Naive Bayes doesn't work with negative values. Plus, it performed the worst previously, so I don't think dropping it out will make any difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models to train\n",
    "models = {\n",
    "    'Logistic regression':LogisticRegression(random_state=42),\n",
    "    'Decision tree':DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "    'Random forest':RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    'Adaboost':AdaBoostClassifier(random_state=42),\n",
    "    'XGBoost':XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "def score_model(models,X_train,y_train,X_test,y_test):\n",
    "    \"\"\"\n",
    "    Scores different models.\n",
    "    Models are trained on NLP pipeline with multioutputclassifier output\n",
    "    Returns a dataframe with model name and recall, roc_auc, f1 scores and brier_score_loss \n",
    "    \n",
    "    \n",
    "    models - a dictionary of different classifiers\n",
    "    X_train, y_train - features and labels to train on\n",
    "    X_test, y_test - features and labels to test for scoring\n",
    "    \"\"\"\n",
    "    \n",
    "    # lists of models' names and scores\n",
    "    model_name, recall, roc_auc, f1, brier_loss = [],[],[],[],[]\n",
    "    \n",
    "    # fit each model and populate score lists\n",
    "    for label,model in models.items():\n",
    "        \n",
    "        model_name.append(label)\n",
    "        \n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('features',FeatureUnion(transformer_list=[\n",
    "                ('tfidf',TfidfVectorizer(tokenizer=process_text, ngram_range=(1,2), max_df=0.95, min_df=2)),\n",
    "                ('wordcount',WordCount())\n",
    "            ])),\n",
    "            ('clf',MultiOutputClassifier(estimator=model))\n",
    "        ])\n",
    "        \n",
    "        pipeline.fit(X_train,y_train)\n",
    "        \n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        y_prob = np.array(pipeline.predict_proba(X_test))\n",
    "        \n",
    "        recall.append(recall_score(y_test,y_pred, average='weighted'))\n",
    "        roc_auc.append(evaluate_proba(y_test,y_prob,metric='roc_auc_score'))\n",
    "        f1.append(f1_score(y_test,y_pred, average='weighted'))\n",
    "        brier_loss.append(evaluate_proba(y_test,y_prob,metric='brier_score_loss'))\n",
    "        \n",
    "        \n",
    "        \n",
    "    # dataframe\n",
    "    df = pd.DataFrame({'model_name':model_name,\n",
    "                       'recall_score':recall,\n",
    "                       'roc_auc_score':roc_auc,\n",
    "                       'f1_score':f1,\n",
    "                       'brier_score_loss':brier_loss})\n",
    "    df = df.sort_values(by=['recall_score','roc_auc_score','f1_score'], ascending=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33min 51s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>brier_score_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.628594</td>\n",
       "      <td>0.677532</td>\n",
       "      <td>0.587169</td>\n",
       "      <td>0.090209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.604177</td>\n",
       "      <td>0.831996</td>\n",
       "      <td>0.643115</td>\n",
       "      <td>0.040343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.570924</td>\n",
       "      <td>0.818169</td>\n",
       "      <td>0.618956</td>\n",
       "      <td>0.225262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>0.534297</td>\n",
       "      <td>0.858119</td>\n",
       "      <td>0.581687</td>\n",
       "      <td>0.041291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>0.516145</td>\n",
       "      <td>0.830301</td>\n",
       "      <td>0.556463</td>\n",
       "      <td>0.041730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  recall_score  roc_auc_score  f1_score  \\\n",
       "1        Decision tree      0.628594       0.677532  0.587169   \n",
       "4              XGBoost      0.604177       0.831996  0.643115   \n",
       "3             Adaboost      0.570924       0.818169  0.618956   \n",
       "0  Logistic regression      0.534297       0.858119  0.581687   \n",
       "2        Random forest      0.516145       0.830301  0.556463   \n",
       "\n",
       "   brier_score_loss  \n",
       "1          0.090209  \n",
       "4          0.040343  \n",
       "3          0.225262  \n",
       "0          0.041291  \n",
       "2          0.041730  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "scores_wc = score_model(models,X_train,y_train,X_test,y_test)\n",
    "scores_wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the only classifier that improved is Decision tree. Others either did not improve or got worse. Although, Decision tree has the highest recall score now (around 0.63), XGBoost still looks more balanced with roc_auc score around 0.83, highest F1 score at 0.64, lowest brier loss of 0.04 and second highest recall score at 0.6. So, I'll continue on with XGBoost classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since adding word count did nothing in terms of improving classifier, I'm not going to add it to the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we have our overall best performing classifier. Now it's time to tune the pipeline trying to get a better score. I'll use GridSearch for that. Since this process takes a lot of time, I'll try tuning only few parameters: 2 parameters for TfIdfVectorizer and 3 parameters for XGBoost clssifier. Also I'll use only 2-fold fit and recall weighted score as scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, let's evaluate our pipeline with only XGBoost classifier as estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline with chosen classifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('features',TfidfVectorizer(tokenizer=process_text, ngram_range=(1,2), max_df=0.95, min_df=2)),\n",
    "    ('clf',MultiOutputClassifier(XGBClassifier(random_state=42)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to evaluate chosen classifier\n",
    "def eval_model(pipeline=pipeline,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test):\n",
    "    \"\"\"\n",
    "    Evaluates a chosen model.\n",
    "    pipeline - model (pipeline) to evaluate,\n",
    "    X_train, y_train - features and labels to train on\n",
    "    X_test, y_test - features and labels to evaluate the model\n",
    "    Returns a dataframe with model's recall (weighted), roc_auc, f1 (weighted) scores and briesr score loss\n",
    "    \"\"\"\n",
    "    \n",
    "    # train the model\n",
    "    pipeline.fit(X_train,y_train)\n",
    "    \n",
    "    # predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_prob = np.array(pipeline.predict_proba(X_test))\n",
    "    \n",
    "    # evaluations in dataframe\n",
    "    evaluations = pd.DataFrame({'recall_score':[recall_score(y_test,y_pred, average='weighted')],\n",
    "                                'roc_auc_score':[evaluate_proba(y_test, y_prob, metric='roc_auc_score')],\n",
    "                                'f1_score':[f1_score(y_test,y_pred, average='weighted')],\n",
    "                                'brier_score_loss':[evaluate_proba(y_test, y_prob, metric='brier_score_loss')]})\n",
    "    \n",
    "    return evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 25s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>brier_score_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.603534</td>\n",
       "      <td>0.830475</td>\n",
       "      <td>0.641227</td>\n",
       "      <td>0.04031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recall_score  roc_auc_score  f1_score  brier_score_loss\n",
       "0      0.603534       0.830475  0.641227           0.04031"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate\n",
    "eval_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the Grid Search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('features',TfidfVectorizer(tokenizer=process_text, ngram_range=(1,2), max_df=0.95, min_df=2)),\n",
    "    ('clf',MultiOutputClassifier(XGBClassifier(random_state=42)))\n",
    "])\n",
    "\n",
    "# parameters to tune\n",
    "params = {\n",
    "    'features__ngram_range':[(1,2),(1,3)],\n",
    "    'features__max_df':[0.95,0.5,0.3],\n",
    "    'clf__estimator__n_estimators':[500,1000],\n",
    "    'clf__estimator__max_depth':range(6,8),\n",
    "    'clf__estimator__eta':[0.01,0.1]\n",
    "}\n",
    "\n",
    "\n",
    "# model\n",
    "model = GridSearchCV(estimator=pipeline, param_grid=params, cv=2, scoring='recall_weighted', verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2), score=0.559, total=17.8min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 17.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2), score=0.558, total=17.2min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 34.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3), score=0.559, total=17.9min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 52.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3), score=0.559, total=19.2min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 72.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2), score=0.559, total=16.1min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 88.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2), score=0.558, total=17.2min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 105.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3), score=0.559, total=19.6min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 125.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3), score=0.559, total=20.2min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 145.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2), score=0.559, total=16.2min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 161.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2), score=0.558, total=16.8min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3), score=0.559, total=17.6min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3), score=0.559, total=19.0min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2), score=0.577, total=29.7min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2), score=0.577, total=31.9min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3), score=0.579, total=33.8min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3), score=0.579, total=36.3min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2), score=0.577, total=30.6min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2), score=0.577, total=32.0min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3), score=0.579, total=33.6min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3), score=0.579, total=36.2min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2), score=0.577, total=30.3min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2), score=0.577, total=32.6min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3), score=0.579, total=35.3min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3), score=0.579, total=38.9min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2), score=0.565, total=19.2min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2), score=0.564, total=19.0min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3), score=0.565, total=19.9min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3), score=0.565, total=22.6min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2), score=0.565, total=19.3min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2), score=0.564, total=19.5min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3), score=0.565, total=19.2min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3), score=0.565, total=20.4min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2), score=0.565, total=17.1min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2), score=0.564, total=17.9min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3), score=0.565, total=19.1min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3), score=0.565, total=20.4min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2), score=0.581, total=31.5min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2), score=0.581, total=33.2min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3), score=0.583, total=34.8min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3), score=0.583, total=37.8min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2), score=0.581, total=31.4min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2), score=0.581, total=33.3min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3), score=0.583, total=35.3min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3), score=0.583, total=37.9min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2), score=0.581, total=31.4min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2), score=0.581, total=33.3min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3), score=0.583, total=35.1min\n",
      "[CV] clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.01, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3), score=0.583, total=37.7min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2), score=0.596, total=14.7min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2), score=0.603, total=16.0min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3), score=0.600, total=16.3min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3), score=0.602, total=18.1min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2), score=0.596, total=14.8min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2), score=0.603, total=15.4min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3), score=0.600, total=16.6min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3), score=0.602, total=17.9min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2), score=0.596, total=14.8min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2), score=0.603, total=15.7min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3), score=0.600, total=16.7min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3), score=0.602, total=17.5min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2), score=0.597, total=28.3min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2), score=0.604, total=29.8min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3), score=0.601, total=31.1min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3), score=0.604, total=33.5min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2), score=0.597, total=27.7min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2), score=0.604, total=29.1min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3), score=0.601, total=31.2min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3), score=0.604, total=33.3min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2), score=0.597, total=27.8min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2), score=0.604, total=29.2min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3), score=0.601, total=30.8min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=6, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3), score=0.604, total=33.5min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2), score=0.597, total=15.9min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 2), score=0.603, total=16.6min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3), score=0.599, total=17.2min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.95, features__ngram_range=(1, 3), score=0.603, total=18.6min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2), score=0.597, total=15.6min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 2), score=0.603, total=16.5min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3), score=0.599, total=17.6min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.5, features__ngram_range=(1, 3), score=0.603, total=19.0min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2), score=0.597, total=15.8min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 2), score=0.603, total=16.5min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3), score=0.599, total=17.5min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=500, features__max_df=0.3, features__ngram_range=(1, 3), score=0.603, total=18.8min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2), score=0.595, total=29.4min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 2), score=0.603, total=30.9min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3), score=0.597, total=32.7min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.95, features__ngram_range=(1, 3), score=0.602, total=35.3min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2), score=0.595, total=29.2min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 2), score=0.603, total=30.8min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3), score=0.597, total=32.7min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.5, features__ngram_range=(1, 3), score=0.602, total=35.8min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2), score=0.595, total=29.2min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 2), score=0.603, total=30.8min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3), score=0.597, total=32.7min\n",
      "[CV] clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3) \n",
      "[CV]  clf__estimator__eta=0.1, clf__estimator__max_depth=7, clf__estimator__n_estimators=1000, features__max_df=0.3, features__ngram_range=(1, 3), score=0.602, total=35.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed: 2413.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1d 17h 26min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('features',\n",
       "                                        TfidfVectorizer(max_df=0.95, min_df=2,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        tokenizer=<function process_text at 0x000002024AF60B88>)),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=XGBClassifier(base_score=None,\n",
       "                                                                                      booster=None,\n",
       "                                                                                      colsample_bylevel=None,\n",
       "                                                                                      colsample_bynode=None,\n",
       "                                                                                      colsample_bytree=None,\n",
       "                                                                                      gamma=None,\n",
       "                                                                                      gpu_id=None,\n",
       "                                                                                      importance_t...\n",
       "                                                                                      reg_lambda=None,\n",
       "                                                                                      scale_pos_weight=None,\n",
       "                                                                                      subsample=None,\n",
       "                                                                                      tree_method=None,\n",
       "                                                                                      validate_parameters=None,\n",
       "                                                                                      verbosity=None)))]),\n",
       "             param_grid={'clf__estimator__eta': [0.01, 0.1],\n",
       "                         'clf__estimator__max_depth': range(6, 8),\n",
       "                         'clf__estimator__n_estimators': [500, 1000],\n",
       "                         'features__max_df': [0.95, 0.5, 0.3],\n",
       "                         'features__ngram_range': [(1, 2), (1, 3)]},\n",
       "             scoring='recall_weighted', verbose=10)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__eta': 0.1,\n",
       " 'clf__estimator__max_depth': 6,\n",
       " 'clf__estimator__n_estimators': 1000,\n",
       " 'features__max_df': 0.95,\n",
       " 'features__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's use the best found parameters while building the pipeline. Also I want to combine train and test sets into one training set. Then use it for pipeline training and evaluate the model on the evaluation set (X_eval, y_eval). And I want to change evaluation function a bit so that trained classifier is saved as .pkl file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to evaluate and save trained classifier\n",
    "def eval_model(pipeline=pipeline,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test):\n",
    "    \"\"\"\n",
    "    Evaluates a chosen model.\n",
    "    pipeline - model (pipeline) to evaluate,\n",
    "    X_train, y_train - features and labels to train on\n",
    "    X_test, y_test - features and labels to evaluate the model\n",
    "    Returns a dataframe with model's recall (weighted), roc_auc, f1 (weighted) scores and briesr score loss\n",
    "    \"\"\"\n",
    "    \n",
    "    # train the model\n",
    "    pipeline.fit(X_train,y_train)\n",
    "    \n",
    "    # predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_prob = np.array(pipeline.predict_proba(X_test))\n",
    "    \n",
    "    # evaluations in dataframe\n",
    "    evaluations = pd.DataFrame({'recall_score':[recall_score(y_test,y_pred, average='weighted')],\n",
    "                                'roc_auc_score':[evaluate_proba(y_test, y_prob, metric='roc_auc_score')],\n",
    "                                'f1_score':[f1_score(y_test,y_pred, average='weighted')],\n",
    "                                'brier_score_loss':[evaluate_proba(y_test, y_prob, metric='brier_score_loss')]})\n",
    "    \n",
    "    # save classifier\n",
    "    pickle.dump(pipeline, open('trained_classifier.pkl','wb'))\n",
    "    \n",
    "    return evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline with tuned parameters\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('features',TfidfVectorizer(tokenizer=process_text, ngram_range=(1,3), max_df=0.95, min_df=2)),\n",
    "    ('clf',MultiOutputClassifier(XGBClassifier(max_depth=6, n_estimators=1000, eta=0.1, random_state=42)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.concat([X_train,X_test])\n",
    "train_y = pd.concat([y_train,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 36min 25s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>brier_score_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.611016</td>\n",
       "      <td>0.808242</td>\n",
       "      <td>0.651459</td>\n",
       "      <td>0.039614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recall_score  roc_auc_score  f1_score  brier_score_loss\n",
       "0      0.611016       0.808242  0.651459          0.039614"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate\n",
    "eval_model(pipeline,train_X,train_y,X_eval,y_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that with tuned parameters our classifier performed almost the same as with default parameters (recall and f1 scores and brier score loss are a bit better while roc_auc score is a bit worse) which I think is a good sign considering it was tested on previously unseen test set. This model was saved and will now be used in web app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full scrip for ML pipeline can be found in train_classifier.py file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
